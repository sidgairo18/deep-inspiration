# deep-inspiration
A deep network to generate inspirational quotes.

## Sample output of the Trained LSTM on the below data.

```
1. ah telling strength.
2. when you are not to think to be a position of solitude for made a movie.
3. i did that that's who i can actually want to go to say ourselves on that that is wearing which there is no strength of the face of a major or the problem and the same.
4. when i was a sea colory and a little control when you're a lighting or any political amitation, and there's no party and i'll go on it.
5. all my mark area. i would be a supported studency. they don't wear a bad, which i couldn't decide to start themselves all i'm starting and i choose or an independence of the persons that i would have that in it.. what's gon's angishing. i don't have the past and the student i wasn't the only state, who is to build anybody who seems to succeed.
6. it's always still to be as a private character.
7. those who did not stand there a serious company, it is such as incredible.
8. the free camera were this world without success. but if the confessors want to see me worth one to that that is working through the soul.
```

## Model 
The network model is a variant of [CharRNN](https://github.com/karpathy/char-rnn). It is a 2-Layer LSTM with 512 hidden units.

## Training Data
Training Data are ~36K quotes taken from [Quotables](https://github.com/alvations/Quotables)

## Dependencies

* PyTorch
* Numpy
* and others

## Code Reference

* Most of the implementation has been picked directly from user [albertlai431's](https://github.com/albertlai431/Machine-Learning/tree/master/Text%20Generation) Machie-Learning/TextGeneration work.
* He has also written a pretty useful blog on [Medium](https://towardsdatascience.com/writing-like-shakespeare-with-machine-learning-in-pytorch-d77f851d910c).

## Model Weigths

* Can be found in /models directory


